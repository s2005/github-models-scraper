[
  {
    "id": "DeepSeek-R1-0528",
    "registry": "azureml-deepseek",
    "name": "DeepSeek-R1-0528",
    "original_name": "DeepSeek-R1-0528",
    "friendly_name": "DeepSeek-R1-0528",
    "task": "chat-completion",
    "publisher": "DeepSeek",
    "license": "",
    "description": "",
    "summary": "The DeepSeek R1 0528 model has improved reasoning capabilities, this version also offers a reduced hallucination rate, enhanced support for function calling, and better experience for vibe coding.",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "reasoning",
      "coding",
      "agents"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 128000,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-deepseek/DeepSeek-R1-0528",
    "page": 1
  },
  {
    "id": "grok-3-mini",
    "registry": "azureml-xai",
    "name": "Grok 3 Mini",
    "original_name": "grok-3-mini",
    "friendly_name": "Grok 3 Mini",
    "task": "chat-completion",
    "publisher": "xAI",
    "license": "",
    "description": "",
    "summary": "Grok 3 Mini is a lightweight model that thinks before responding. Trained on mathematic and scientific problems, it is great for logic-based tasks.",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "agents",
      "reasoning",
      "coding"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 131072,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-xai/grok-3-mini",
    "page": 1
  },
  {
    "id": "grok-3",
    "registry": "azureml-xai",
    "name": "Grok 3",
    "original_name": "grok-3",
    "friendly_name": "Grok 3",
    "task": "chat-completion",
    "publisher": "xAI",
    "license": "",
    "description": "",
    "summary": "Grok 3 is xAI's debut model, pretrained by Colossus at supermassive scale to excel in specialized domains like finance, healthcare, and the law.",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "understanding",
      "instruction",
      "summarization"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 131072,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-xai/grok-3",
    "page": 1
  },
  {
    "id": "mistral-medium-2505",
    "registry": "azureml-mistral",
    "name": "Mistral Medium 3 (25.05)",
    "original_name": "mistral-medium-2505",
    "friendly_name": "Mistral Medium 3 (25.05)",
    "task": "chat-completion",
    "publisher": "Mistral AI",
    "license": "",
    "description": "",
    "summary": "Mistral Medium 3 is an advanced Large Language Model (LLM) with state-of-the-art reasoning, knowledge, coding and vision capabilities.",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "multipurpose",
      "vision"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 128000,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-mistral/mistral-medium-2505",
    "page": 1
  },
  {
    "id": "Phi-4-reasoning",
    "registry": "azureml",
    "name": "Phi-4-Reasoning",
    "original_name": "Phi-4-reasoning",
    "friendly_name": "Phi-4-Reasoning",
    "task": "chat-completion",
    "publisher": "Microsoft",
    "license": "",
    "description": "",
    "summary": "State-of-the-art open-weight reasoning model.",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "reasoning",
      "large context",
      "low latency"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 32768,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml/Phi-4-reasoning",
    "page": 1
  },
  {
    "id": "Phi-4-mini-reasoning",
    "registry": "azureml",
    "name": "Phi-4-mini-reasoning",
    "original_name": "Phi-4-mini-reasoning",
    "friendly_name": "Phi-4-mini-reasoning",
    "task": "chat-completion",
    "publisher": "Microsoft",
    "license": "",
    "description": "",
    "summary": "Lightweight math reasoning model optimized for multi-step problem solving",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "reasoning",
      "large context",
      "low latency"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 128000,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml/Phi-4-mini-reasoning",
    "page": 1
  },
  {
    "id": "MAI-DS-R1",
    "registry": "azureml",
    "name": "MAI-DS-R1",
    "original_name": "MAI-DS-R1",
    "friendly_name": "MAI-DS-R1",
    "task": "chat-completion",
    "publisher": "Microsoft",
    "license": "",
    "description": "",
    "summary": "MAI-DS-R1 is a DeepSeek-R1 reasoning model that has been post-trained by the Microsoft AI team to fill in information gaps in the previous version of the model and improve its harm protections while maintaining R1 reasoning capabilities.",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "reasoning",
      "coding",
      "agents"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 128000,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml/MAI-DS-R1",
    "page": 1
  },
  {
    "id": "o4-mini",
    "registry": "azure-openai",
    "name": "OpenAI o4-mini",
    "original_name": "o4-mini",
    "friendly_name": "OpenAI o4-mini",
    "task": "chat-completion",
    "publisher": "OpenAI",
    "license": "",
    "description": "",
    "summary": "o4-mini includes significant improvements on quality and safety while supporting the existing features of o3-mini and delivering comparable or better performance.",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "multipurpose",
      "multilingual",
      "multimodal"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 100000,
    "max_input_tokens": 200000,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azure-openai/o4-mini",
    "page": 1
  },
  {
    "id": "o3",
    "registry": "azure-openai",
    "name": "OpenAI o3",
    "original_name": "o3",
    "friendly_name": "OpenAI o3",
    "task": "chat-completion",
    "publisher": "OpenAI",
    "license": "",
    "description": "",
    "summary": "o3 includes significant improvements on quality and safety while supporting the existing features of o1 and delivering comparable or better performance.",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "multipurpose",
      "multilingual",
      "multimodal"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 100000,
    "max_input_tokens": 200000,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azure-openai/o3",
    "page": 1
  },
  {
    "id": "cohere-command-a",
    "registry": "azureml-cohere",
    "name": "Cohere Command A",
    "original_name": "cohere-command-a",
    "friendly_name": "Cohere Command A",
    "task": "chat-completion",
    "publisher": "Cohere",
    "license": "",
    "description": "",
    "summary": "Command A is a highly efficient generative model that excels at agentic and multilingual use cases.",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "rag",
      "multilingual"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 131072,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-cohere/cohere-command-a",
    "page": 1
  },
  {
    "id": "gpt-4-1-mini",
    "registry": "azure-openai",
    "name": "OpenAI GPT-4.1-mini",
    "original_name": "gpt-4-1-mini",
    "friendly_name": "OpenAI GPT-4.1-mini",
    "task": "chat-completion",
    "publisher": "OpenAI",
    "license": "",
    "description": "",
    "summary": "gpt-4.1-mini outperform gpt-4o-mini across the board, with major gains in coding, instruction following, and long-context handling",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "multipurpose",
      "multilingual",
      "multimodal"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 32768,
    "max_input_tokens": 1048576,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azure-openai/gpt-4-1-mini",
    "page": 1
  },
  {
    "id": "gpt-4-1-nano",
    "registry": "azure-openai",
    "name": "OpenAI GPT-4.1-nano",
    "original_name": "gpt-4-1-nano",
    "friendly_name": "OpenAI GPT-4.1-nano",
    "task": "chat-completion",
    "publisher": "OpenAI",
    "license": "",
    "description": "",
    "summary": "gpt-4.1-nano provides gains in coding, instruction following, and long-context handling along with lower latency and cost",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "multipurpose",
      "multilingual",
      "multimodal"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 32768,
    "max_input_tokens": 1048576,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azure-openai/gpt-4-1-nano",
    "page": 1
  },
  {
    "id": "gpt-4-1",
    "registry": "azure-openai",
    "name": "OpenAI GPT-4.1",
    "original_name": "gpt-4-1",
    "friendly_name": "OpenAI GPT-4.1",
    "task": "chat-completion",
    "publisher": "OpenAI",
    "license": "",
    "description": "",
    "summary": "gpt-4.1 outperforms gpt-4o across the board, with major gains in coding, instruction following, and long-context understanding",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "multipurpose",
      "multilingual",
      "multimodal"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 32768,
    "max_input_tokens": 1048576,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azure-openai/gpt-4-1",
    "page": 1
  },
  {
    "id": "Llama-4-Scout-17B-16E-Instruct",
    "registry": "azureml-meta",
    "name": "Llama 4 Scout 17B 16E Instruct",
    "original_name": "Llama-4-Scout-17B-16E-Instruct",
    "friendly_name": "Llama 4 Scout 17B 16E Instruct",
    "task": "chat-completion",
    "publisher": "Meta",
    "license": "",
    "description": "",
    "summary": "Llama 4 Scout 17B 16E Instruct is great at multi-document summarization, parsing extensive user activity for personalized tasks, and reasoning over vast codebases.",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "multimodal",
      "conversation",
      "multilingual"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 10000000,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-meta/Llama-4-Scout-17B-16E-Instruct",
    "page": 1
  },
  {
    "id": "Llama-4-Maverick-17B-128E-Instruct-FP8",
    "registry": "azureml-meta",
    "name": "Llama 4 Maverick 17B 128E Instruct FP8",
    "original_name": "Llama-4-Maverick-17B-128E-Instruct-FP8",
    "friendly_name": "Llama 4 Maverick 17B 128E Instruct FP8",
    "task": "chat-completion",
    "publisher": "Meta",
    "license": "",
    "description": "",
    "summary": "Llama 4 Maverick 17B 128E Instruct FP8 is great at precise image understanding and creative writing, offering high quality at a lower price compared to Llama 3.3 70B",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "multimodal",
      "conversation",
      "multilingual"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 1000000,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-meta/Llama-4-Maverick-17B-128E-Instruct-FP8",
    "page": 1
  },
  {
    "id": "Phi-4-multimodal-instruct",
    "registry": "azureml",
    "name": "Phi-4-multimodal-instruct",
    "original_name": "Phi-4-multimodal-instruct",
    "friendly_name": "Phi-4-multimodal-instruct",
    "task": "chat-completion",
    "publisher": "Microsoft",
    "license": "",
    "description": "",
    "summary": "First small multimodal model to have 3 modality inputs (text, audio, image), excelling in quality and efficiency",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "vision",
      "audio",
      "summarization"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 128000,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml/Phi-4-multimodal-instruct",
    "page": 1
  },
  {
    "id": "Phi-4-mini-instruct",
    "registry": "azureml",
    "name": "Phi-4-mini-instruct",
    "original_name": "Phi-4-mini-instruct",
    "friendly_name": "Phi-4-mini-instruct",
    "task": "chat-completion",
    "publisher": "Microsoft",
    "license": "",
    "description": "",
    "summary": "3.8B parameters Small Language Model outperforming larger models in reasoning, math, coding, and function-calling",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "reasoning",
      "agents",
      "multilingual"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 128000,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml/Phi-4-mini-instruct",
    "page": 1
  },
  {
    "id": "Phi-4",
    "registry": "azureml",
    "name": "Phi-4",
    "original_name": "Phi-4",
    "friendly_name": "Phi-4",
    "task": "chat-completion",
    "publisher": "Microsoft",
    "license": "",
    "description": "",
    "summary": "Phi-4 14B, a highly capable model for low latency scenarios.",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "reasoning",
      "understanding",
      "low latency"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 16384,
    "max_input_tokens": 16384,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml/Phi-4",
    "page": 1
  },
  {
    "id": "Phi-3-5-vision-instruct",
    "registry": "azureml",
    "name": "Phi-3.5-vision instruct (128k)",
    "original_name": "Phi-3-5-vision-instruct",
    "friendly_name": "Phi-3.5-vision instruct (128k)",
    "task": "chat-completion",
    "publisher": "Microsoft",
    "license": "",
    "description": "",
    "summary": "Refresh of Phi-3-vision model.",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "multimodal",
      "reasoning",
      "low latency"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 131072,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml/Phi-3-5-vision-instruct",
    "page": 1
  },
  {
    "id": "Phi-3-5-MoE-instruct",
    "registry": "azureml",
    "name": "Phi-3.5-MoE instruct (128k)",
    "original_name": "Phi-3-5-MoE-instruct",
    "friendly_name": "Phi-3.5-MoE instruct (128k)",
    "task": "chat-completion",
    "publisher": "Microsoft",
    "license": "",
    "description": "",
    "summary": "A new mixture of experts model",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "reasoning",
      "understanding",
      "low latency"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 131072,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml/Phi-3-5-MoE-instruct",
    "page": 1
  },
  {
    "id": "Phi-3-5-mini-instruct",
    "registry": "azureml",
    "name": "Phi-3.5-mini instruct (128k)",
    "original_name": "Phi-3-5-mini-instruct",
    "friendly_name": "Phi-3.5-mini instruct (128k)",
    "task": "chat-completion",
    "publisher": "Microsoft",
    "license": "",
    "description": "",
    "summary": "Refresh of Phi-3-mini model.",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "reasoning",
      "understanding",
      "low latency"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 131072,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml/Phi-3-5-mini-instruct",
    "page": 2
  },
  {
    "id": "Phi-3-small-8k-instruct",
    "registry": "azureml",
    "name": "Phi-3-small instruct (8k)",
    "original_name": "Phi-3-small-8k-instruct",
    "friendly_name": "Phi-3-small instruct (8k)",
    "task": "chat-completion",
    "publisher": "Microsoft",
    "license": "",
    "description": "",
    "summary": "A 7B parameters model, proves better quality than Phi-3-mini, with a focus on high-quality, reasoning-dense data.",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "reasoning",
      "understanding"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 131072,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml/Phi-3-small-8k-instruct",
    "page": 2
  },
  {
    "id": "Phi-3-small-128k-instruct",
    "registry": "azureml",
    "name": "Phi-3-small instruct (128k)",
    "original_name": "Phi-3-small-128k-instruct",
    "friendly_name": "Phi-3-small instruct (128k)",
    "task": "chat-completion",
    "publisher": "Microsoft",
    "license": "",
    "description": "",
    "summary": "Same Phi-3-small model, but with a larger context size for RAG or few shot prompting.",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "reasoning",
      "understanding",
      "large context"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 131072,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml/Phi-3-small-128k-instruct",
    "page": 2
  },
  {
    "id": "Phi-3-mini-4k-instruct",
    "registry": "azureml",
    "name": "Phi-3-mini instruct (4k)",
    "original_name": "Phi-3-mini-4k-instruct",
    "friendly_name": "Phi-3-mini instruct (4k)",
    "task": "chat-completion",
    "publisher": "Microsoft",
    "license": "",
    "description": "",
    "summary": "Tiniest member of the Phi-3 family. Optimized for both quality and low latency.",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "reasoning",
      "understanding",
      "low latency"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 4096,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml/Phi-3-mini-4k-instruct",
    "page": 2
  },
  {
    "id": "Phi-3-mini-128k-instruct",
    "registry": "azureml",
    "name": "Phi-3-mini instruct (128k)",
    "original_name": "Phi-3-mini-128k-instruct",
    "friendly_name": "Phi-3-mini instruct (128k)",
    "task": "chat-completion",
    "publisher": "Microsoft",
    "license": "",
    "description": "",
    "summary": "Same Phi-3-mini model, but with a larger context size for RAG or few shot prompting.",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "reasoning",
      "understanding",
      "low latency"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 131072,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml/Phi-3-mini-128k-instruct",
    "page": 2
  },
  {
    "id": "Phi-3-medium-4k-instruct",
    "registry": "azureml",
    "name": "Phi-3-medium instruct (4k)",
    "original_name": "Phi-3-medium-4k-instruct",
    "friendly_name": "Phi-3-medium instruct (4k)",
    "task": "chat-completion",
    "publisher": "Microsoft",
    "license": "",
    "description": "",
    "summary": "A 14B parameters model, proves better quality than Phi-3-mini, with a focus on high-quality, reasoning-dense data.",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "reasoning",
      "understanding"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 4096,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml/Phi-3-medium-4k-instruct",
    "page": 2
  },
  {
    "id": "Phi-3-medium-128k-instruct",
    "registry": "azureml",
    "name": "Phi-3-medium instruct (128k)",
    "original_name": "Phi-3-medium-128k-instruct",
    "friendly_name": "Phi-3-medium instruct (128k)",
    "task": "chat-completion",
    "publisher": "Microsoft",
    "license": "",
    "description": "",
    "summary": "Same Phi-3-medium model, but with a larger context size for RAG or few shot prompting.",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "reasoning",
      "understanding",
      "large context"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 131072,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml/Phi-3-medium-128k-instruct",
    "page": 2
  },
  {
    "id": "text-embedding-3-small",
    "registry": "azure-openai",
    "name": "OpenAI Text Embedding 3 (small)",
    "original_name": "text-embedding-3-small",
    "friendly_name": "OpenAI Text Embedding 3 (small)",
    "task": "embeddings",
    "publisher": "OpenAI",
    "license": "",
    "description": "",
    "summary": "Text-embedding-3 series models are the latest and most capable embedding model from OpenAI.",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "rag"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 0,
    "max_input_tokens": 8191,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azure-openai/text-embedding-3-small",
    "page": 2
  },
  {
    "id": "text-embedding-3-large",
    "registry": "azure-openai",
    "name": "OpenAI Text Embedding 3 (large)",
    "original_name": "text-embedding-3-large",
    "friendly_name": "OpenAI Text Embedding 3 (large)",
    "task": "embeddings",
    "publisher": "OpenAI",
    "license": "",
    "description": "",
    "summary": "Text-embedding-3 series models are the latest and most capable embedding model from OpenAI.",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "rag"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 0,
    "max_input_tokens": 8191,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azure-openai/text-embedding-3-large",
    "page": 2
  },
  {
    "id": "o3-mini",
    "registry": "azure-openai",
    "name": "OpenAI o3-mini",
    "original_name": "o3-mini",
    "friendly_name": "OpenAI o3-mini",
    "task": "chat-completion",
    "publisher": "OpenAI",
    "license": "",
    "description": "",
    "summary": "o3-mini includes the o1 features with significant cost-efficiencies for scenarios requiring high performance.",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "reasoning",
      "multilingual",
      "coding"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 100000,
    "max_input_tokens": 200000,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azure-openai/o3-mini",
    "page": 2
  },
  {
    "id": "o1-preview",
    "registry": "azure-openai",
    "name": "OpenAI o1-preview",
    "original_name": "o1-preview",
    "friendly_name": "OpenAI o1-preview",
    "task": "chat-completion",
    "publisher": "OpenAI",
    "license": "",
    "description": "",
    "summary": "Focused on advanced reasoning and solving complex problems, including math and science tasks. Ideal for applications that require deep contextual understanding and agentic workflows.",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "reasoning",
      "multilingual",
      "coding"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 32768,
    "max_input_tokens": 128000,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azure-openai/o1-preview",
    "page": 2
  },
  {
    "id": "o1-mini",
    "registry": "azure-openai",
    "name": "OpenAI o1-mini",
    "original_name": "o1-mini",
    "friendly_name": "OpenAI o1-mini",
    "task": "chat-completion",
    "publisher": "OpenAI",
    "license": "",
    "description": "",
    "summary": "Smaller, faster, and 80% cheaper than o1-preview, performs well at code generation and small context operations.",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "reasoning",
      "multilingual",
      "coding"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 65536,
    "max_input_tokens": 128000,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azure-openai/o1-mini",
    "page": 2
  },
  {
    "id": "o1",
    "registry": "azure-openai",
    "name": "OpenAI o1",
    "original_name": "o1",
    "friendly_name": "OpenAI o1",
    "task": "chat-completion",
    "publisher": "OpenAI",
    "license": "",
    "description": "",
    "summary": "Focused on advanced reasoning and solving complex problems, including math and science tasks. Ideal for applications that require deep contextual understanding and agentic workflows.",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "reasoning",
      "multilingual",
      "coding"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 100000,
    "max_input_tokens": 200000,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azure-openai/o1",
    "page": 2
  },
  {
    "id": "gpt-4o-mini",
    "registry": "azure-openai",
    "name": "OpenAI GPT-4o mini",
    "original_name": "gpt-4o-mini",
    "friendly_name": "OpenAI GPT-4o mini",
    "task": "chat-completion",
    "publisher": "OpenAI",
    "license": "",
    "description": "",
    "summary": "An affordable, efficient AI solution for diverse text and image tasks.",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "multipurpose",
      "multilingual",
      "multimodal"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 131072,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azure-openai/gpt-4o-mini",
    "page": 2
  },
  {
    "id": "gpt-4o",
    "registry": "azure-openai",
    "name": "OpenAI GPT-4o",
    "original_name": "gpt-4o",
    "friendly_name": "OpenAI GPT-4o",
    "task": "chat-completion",
    "publisher": "OpenAI",
    "license": "",
    "description": "",
    "summary": "OpenAI's most advanced multimodal model in the gpt-4o family. Can handle both text and image inputs.",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "multipurpose",
      "multilingual",
      "multimodal"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 16384,
    "max_input_tokens": 131072,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azure-openai/gpt-4o",
    "page": 2
  },
  {
    "id": "mistral-small-2503",
    "registry": "azureml-mistral",
    "name": "Mistral Small 3.1",
    "original_name": "mistral-small-2503",
    "friendly_name": "Mistral Small 3.1",
    "task": "chat-completion",
    "publisher": "Mistral AI",
    "license": "",
    "description": "",
    "summary": "Enhanced Mistral Small 3 with multimodal capabilities and a 128k context length.",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "multipurpose",
      "vision",
      "multimodal"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 128000,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-mistral/mistral-small-2503",
    "page": 2
  },
  {
    "id": "Mistral-Nemo",
    "registry": "azureml-mistral",
    "name": "Mistral Nemo",
    "original_name": "Mistral-Nemo",
    "friendly_name": "Mistral Nemo",
    "task": "chat-completion",
    "publisher": "Mistral AI",
    "license": "",
    "description": "",
    "summary": "Mistral Nemo is a cutting-edge Language Model (LLM) boasting state-of-the-art reasoning, world knowledge, and coding capabilities within its size category.",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "reasoning",
      "rag",
      "agents"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 131072,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-mistral/Mistral-Nemo",
    "page": 2
  },
  {
    "id": "Mistral-Large-2411",
    "registry": "azureml-mistral",
    "name": "Mistral Large 24.11",
    "original_name": "Mistral-Large-2411",
    "friendly_name": "Mistral Large 24.11",
    "task": "chat-completion",
    "publisher": "Mistral AI",
    "license": "",
    "description": "",
    "summary": "Mistral Large 24.11 offers enhanced system prompts, advanced reasoning and function calling capabilities.",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "reasoning",
      "rag",
      "agents"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 128000,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-mistral/Mistral-Large-2411",
    "page": 2
  },
  {
    "id": "Ministral-3B",
    "registry": "azureml-mistral",
    "name": "Ministral 3B",
    "original_name": "Ministral-3B",
    "friendly_name": "Ministral 3B",
    "task": "chat-completion",
    "publisher": "Mistral AI",
    "license": "",
    "description": "",
    "summary": "Ministral 3B is a state-of-the-art Small Language Model (SLM) optimized for edge computing and on-device applications. As it is designed for low-latency and compute-efficient inference, it it also the perfect model for standard GenAI applications that have",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "low latency",
      "agents",
      "reasoning"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 131072,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-mistral/Ministral-3B",
    "page": 2
  },
  {
    "id": "Meta-Llama-3-1-8B-Instruct",
    "registry": "azureml-meta",
    "name": "Meta-Llama-3.1-8B-Instruct",
    "original_name": "Meta-Llama-3-1-8B-Instruct",
    "friendly_name": "Meta-Llama-3.1-8B-Instruct",
    "task": "chat-completion",
    "publisher": "Meta",
    "license": "",
    "description": "",
    "summary": "The Llama 3.1 instruction tuned text only models are optimized for multilingual dialogue use cases and outperform many of the available open source and closed chat models on common industry benchmarks.",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "conversation"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 131072,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-meta/Meta-Llama-3-1-8B-Instruct",
    "page": 2
  },
  {
    "id": "Meta-Llama-3-1-405B-Instruct",
    "registry": "azureml-meta",
    "name": "Meta-Llama-3.1-405B-Instruct",
    "original_name": "Meta-Llama-3-1-405B-Instruct",
    "friendly_name": "Meta-Llama-3.1-405B-Instruct",
    "task": "chat-completion",
    "publisher": "Meta",
    "license": "",
    "description": "",
    "summary": "The Llama 3.1 instruction tuned text only models are optimized for multilingual dialogue use cases and outperform many of the available open source and closed chat models on common industry benchmarks.",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "conversation"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 131072,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-meta/Meta-Llama-3-1-405B-Instruct",
    "page": 3
  },
  {
    "id": "Llama-3-3-70B-Instruct",
    "registry": "azureml-meta",
    "name": "Llama-3.3-70B-Instruct",
    "original_name": "Llama-3-3-70B-Instruct",
    "friendly_name": "Llama-3.3-70B-Instruct",
    "task": "chat-completion",
    "publisher": "Meta",
    "license": "",
    "description": "",
    "summary": "Llama 3.3 70B Instruct offers enhanced reasoning, math, and instruction following with performance comparable to Llama 3.1 405B.",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "conversation"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 128000,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-meta/Llama-3-3-70B-Instruct",
    "page": 3
  },
  {
    "id": "Llama-3-2-90B-Vision-Instruct",
    "registry": "azureml-meta",
    "name": "Llama-3.2-90B-Vision-Instruct",
    "original_name": "Llama-3-2-90B-Vision-Instruct",
    "friendly_name": "Llama-3.2-90B-Vision-Instruct",
    "task": "chat-completion",
    "publisher": "Meta",
    "license": "",
    "description": "",
    "summary": "Advanced image reasoning capabilities for visual understanding agentic apps.",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "multimodal",
      "reasoning",
      "conversation"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 128000,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-meta/Llama-3-2-90B-Vision-Instruct",
    "page": 3
  },
  {
    "id": "Llama-3-2-11B-Vision-Instruct",
    "registry": "azureml-meta",
    "name": "Llama-3.2-11B-Vision-Instruct",
    "original_name": "Llama-3-2-11B-Vision-Instruct",
    "friendly_name": "Llama-3.2-11B-Vision-Instruct",
    "task": "chat-completion",
    "publisher": "Meta",
    "license": "",
    "description": "",
    "summary": "Excels in image reasoning capabilities on high-res images for visual understanding apps.",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "multimodal",
      "reasoning",
      "conversation"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 128000,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-meta/Llama-3-2-11B-Vision-Instruct",
    "page": 3
  },
  {
    "id": "jais-30b-chat",
    "registry": "azureml-core42",
    "name": "JAIS 30b Chat",
    "original_name": "jais-30b-chat",
    "friendly_name": "JAIS 30b Chat",
    "task": "chat-completion",
    "publisher": "Core42",
    "license": "",
    "description": "",
    "summary": "JAIS 30b Chat is an auto-regressive bilingual LLM for Arabic & English with state-of-the-art capabilities in Arabic.",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "conversation",
      "multilingual",
      "rag"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 8192,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-core42/jais-30b-chat",
    "page": 3
  },
  {
    "id": "DeepSeek-V3-0324",
    "registry": "azureml-deepseek",
    "name": "DeepSeek-V3-0324",
    "original_name": "DeepSeek-V3-0324",
    "friendly_name": "DeepSeek-V3-0324",
    "task": "chat-completion",
    "publisher": "DeepSeek",
    "license": "",
    "description": "",
    "summary": "DeepSeek-V3-0324 demonstrates notable improvements over its predecessor, DeepSeek-V3, in several key aspects, including enhanced reasoning, improved function calling, and superior code generation capabilities.",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "coding",
      "agents"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 128000,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-deepseek/DeepSeek-V3-0324",
    "page": 3
  },
  {
    "id": "DeepSeek-R1",
    "registry": "azureml-deepseek",
    "name": "DeepSeek-R1",
    "original_name": "DeepSeek-R1",
    "friendly_name": "DeepSeek-R1",
    "task": "chat-completion",
    "publisher": "DeepSeek",
    "license": "",
    "description": "",
    "summary": "DeepSeek-R1 excels at reasoning tasks using a step-by-step training process, such as language, scientific reasoning, and coding tasks.",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "reasoning",
      "coding",
      "agents"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 128000,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-deepseek/DeepSeek-R1",
    "page": 3
  },
  {
    "id": "Cohere-embed-v3-multilingual",
    "registry": "azureml-cohere",
    "name": "Cohere Embed v3 Multilingual",
    "original_name": "Cohere-embed-v3-multilingual",
    "friendly_name": "Cohere Embed v3 Multilingual",
    "task": "embeddings",
    "publisher": "Cohere",
    "license": "",
    "description": "",
    "summary": "Cohere Embed Multilingual is the market's leading text representation model used for semantic search, retrieval-augmented generation (RAG), classification, and clustering.",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "rag"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 0,
    "max_input_tokens": 512,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-cohere/Cohere-embed-v3-multilingual",
    "page": 3
  },
  {
    "id": "Cohere-embed-v3-english",
    "registry": "azureml-cohere",
    "name": "Cohere Embed v3 English",
    "original_name": "Cohere-embed-v3-english",
    "friendly_name": "Cohere Embed v3 English",
    "task": "embeddings",
    "publisher": "Cohere",
    "license": "",
    "description": "",
    "summary": "Cohere Embed English is the market's leading text representation model used for semantic search, retrieval-augmented generation (RAG), classification, and clustering.",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "rag"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 0,
    "max_input_tokens": 512,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-cohere/Cohere-embed-v3-english",
    "page": 3
  },
  {
    "id": "Cohere-command-r-plus-08-2024",
    "registry": "azureml-cohere",
    "name": "Cohere Command R+ 08-2024",
    "original_name": "Cohere-command-r-plus-08-2024",
    "friendly_name": "Cohere Command R+ 08-2024",
    "task": "chat-completion",
    "publisher": "Cohere",
    "license": "",
    "description": "",
    "summary": "Command R+ is a state-of-the-art RAG-optimized model designed to tackle enterprise-grade workloads.",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "rag",
      "multilingual"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 131072,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-cohere/Cohere-command-r-plus-08-2024",
    "page": 3
  },
  {
    "id": "Cohere-command-r-08-2024",
    "registry": "azureml-cohere",
    "name": "Cohere Command R 08-2024",
    "original_name": "Cohere-command-r-08-2024",
    "friendly_name": "Cohere Command R 08-2024",
    "task": "chat-completion",
    "publisher": "Cohere",
    "license": "",
    "description": "",
    "summary": "Command R is a scalable generative model targeting RAG and Tool Use to enable production-scale AI for enterprise.",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "rag",
      "multilingual"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 131072,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-cohere/Cohere-command-r-08-2024",
    "page": 3
  },
  {
    "id": "Codestral-2501",
    "registry": "azureml-mistral",
    "name": "Codestral 25.01",
    "original_name": "Codestral-2501",
    "friendly_name": "Codestral 25.01",
    "task": "chat-completion",
    "publisher": "Mistral AI",
    "license": "",
    "description": "",
    "summary": "Codestral 25.01 by Mistral AI is designed for code generation, supporting 80+ programming languages, and optimized for tasks like code completion and fill-in-the-middle",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "reasoning",
      "coding"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 256000,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-mistral/Codestral-2501",
    "page": 3
  },
  {
    "id": "AI21-Jamba-1-5-Mini",
    "registry": "azureml-ai21",
    "name": "AI21 Jamba 1.5 Mini",
    "original_name": "AI21-Jamba-1-5-Mini",
    "friendly_name": "AI21 Jamba 1.5 Mini",
    "task": "chat-completion",
    "publisher": "AI21 Labs",
    "license": "",
    "description": "",
    "summary": "A 52B parameters (12B active) multilingual model, offering a 256K long context window, function calling, structured output, and grounded generation.",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "rag",
      "multilingual",
      "large context"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 262144,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-ai21/AI21-Jamba-1-5-Mini",
    "page": 3
  },
  {
    "id": "AI21-Jamba-1-5-Large",
    "registry": "azureml-ai21",
    "name": "AI21 Jamba 1.5 Large",
    "original_name": "AI21-Jamba-1-5-Large",
    "friendly_name": "AI21 Jamba 1.5 Large",
    "task": "chat-completion",
    "publisher": "AI21 Labs",
    "license": "",
    "description": "",
    "summary": "A 398B parameters (94B active) multilingual model, offering a 256K long context window, function calling, structured output, and grounded generation.",
    "model_family": "unknown",
    "model_version": "",
    "notes": "",
    "tags": [
      "rag",
      "multilingual",
      "large context"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 262144,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-ai21/AI21-Jamba-1-5-Large",
    "page": 3
  }
]