[
  {
    "id": "o3-mini",
    "registry": "azure-openai",
    "name": "OpenAI o3-mini",
    "original_name": "o3-mini",
    "friendly_name": "OpenAI o3-mini",
    "task": "chat-completion",
    "publisher": "OpenAI",
    "license": "",
    "description": "",
    "summary": "o3-mini includes the o1 features with significant cost-efficiencies for scenarios requiring high performance.",
    "model_family": "OpenAI",
    "model_version": "",
    "notes": "",
    "tags": [
      "reasoning",
      "multilingual",
      "coding"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 100000,
    "max_input_tokens": 200000,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azure-openai/o3-mini",
    "page": 1
  },
  {
    "id": "DeepSeek-R1",
    "registry": "azureml-deepseek",
    "name": "DeepSeek-R1",
    "original_name": "DeepSeek-R1",
    "friendly_name": "DeepSeek-R1",
    "task": "chat-completion",
    "publisher": "DeepSeek",
    "license": "",
    "description": "",
    "summary": "DeepSeek-R1 excels at reasoning tasks using a step-by-step training process, such as language, scientific reasoning, and coding tasks.",
    "model_family": "DeepSeek",
    "model_version": "",
    "notes": "",
    "tags": [
      "reasoning",
      "coding",
      "agents"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 128000,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-deepseek/DeepSeek-R1",
    "page": 1
  },
  {
    "id": "Phi-4",
    "registry": "azureml",
    "name": "Phi-4",
    "original_name": "Phi-4",
    "friendly_name": "Phi-4",
    "task": "chat-completion",
    "publisher": "Microsoft",
    "license": "",
    "description": "",
    "summary": "Phi-4 14B, a highly capable model for low latency scenarios.",
    "model_family": "Microsoft",
    "model_version": "",
    "notes": "",
    "tags": [
      "reasoning",
      "understanding",
      "low latency"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 16384,
    "max_input_tokens": 16384,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml/Phi-4",
    "page": 1
  },
  {
    "id": "Codestral-2501",
    "registry": "azureml-mistral",
    "name": "Codestral 25.01",
    "original_name": "Codestral-2501",
    "friendly_name": "Codestral 25.01",
    "task": "chat-completion",
    "publisher": "Mistral AI",
    "license": "",
    "description": "",
    "summary": "Codestral 25.01 by Mistral AI is designed for code generation, supporting 80+ programming languages, and optimized for tasks like code completion and fill-in-the-middle",
    "model_family": "Mistral AI",
    "model_version": "",
    "notes": "",
    "tags": [
      "reasoning",
      "coding"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 256000,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-mistral/Codestral-2501",
    "page": 1
  },
  {
    "id": "o1",
    "registry": "azure-openai",
    "name": "OpenAI o1",
    "original_name": "o1",
    "friendly_name": "OpenAI o1",
    "task": "chat-completion",
    "publisher": "OpenAI",
    "license": "",
    "description": "",
    "summary": "Focused on advanced reasoning and solving complex problems, including math and science tasks. Ideal for applications that require deep contextual understanding and agentic workflows.",
    "model_family": "OpenAI",
    "model_version": "",
    "notes": "",
    "tags": [
      "reasoning",
      "multilingual",
      "coding"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 100000,
    "max_input_tokens": 200000,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azure-openai/o1",
    "page": 1
  },
  {
    "id": "Mistral-Large-2411",
    "registry": "azureml-mistral",
    "name": "Mistral Large 24.11",
    "original_name": "Mistral-Large-2411",
    "friendly_name": "Mistral Large 24.11",
    "task": "chat-completion",
    "publisher": "Mistral AI",
    "license": "",
    "description": "",
    "summary": "Mistral Large 24.11 offers enhanced system prompts, advanced reasoning and function calling capabilities.",
    "model_family": "Mistral AI",
    "model_version": "",
    "notes": "",
    "tags": [
      "reasoning",
      "rag",
      "agents"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 128000,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-mistral/Mistral-Large-2411",
    "page": 1
  },
  {
    "id": "Llama-3-3-70B-Instruct",
    "registry": "azureml-meta",
    "name": "Llama-3.3-70B-Instruct",
    "original_name": "Llama-3-3-70B-Instruct",
    "friendly_name": "Llama-3.3-70B-Instruct",
    "task": "chat-completion",
    "publisher": "Meta",
    "license": "",
    "description": "",
    "summary": "Llama 3.3 70B Instruct offers enhanced reasoning, math, and instruction following with performance comparable to Llama 3.1 405B.",
    "model_family": "Meta",
    "model_version": "",
    "notes": "",
    "tags": [
      "conversation"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 128000,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-meta/Llama-3-3-70B-Instruct",
    "page": 1
  },
  {
    "id": "jais-30b-chat",
    "registry": "azureml-core42",
    "name": "JAIS 30b Chat",
    "original_name": "jais-30b-chat",
    "friendly_name": "JAIS 30b Chat",
    "task": "chat-completion",
    "publisher": "Core42",
    "license": "",
    "description": "",
    "summary": "JAIS 30b Chat is an auto-regressive bilingual LLM for Arabic & English with state-of-the-art capabilities in Arabic.",
    "model_family": "Core42",
    "model_version": "",
    "notes": "",
    "tags": [
      "conversation",
      "multilingual",
      "rag"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 8192,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-core42/jais-30b-chat",
    "page": 1
  },
  {
    "id": "Ministral-3B",
    "registry": "azureml-mistral",
    "name": "Ministral 3B",
    "original_name": "Ministral-3B",
    "friendly_name": "Ministral 3B",
    "task": "chat-completion",
    "publisher": "Mistral AI",
    "license": "",
    "description": "",
    "summary": "Ministral 3B is a state-of-the-art Small Language Model (SLM) optimized for edge computing and on-device applications. As it is designed for low-latency and compute-efficient inference, it it also the perfect model for standard GenAI applications that have",
    "model_family": "Mistral AI",
    "model_version": "",
    "notes": "",
    "tags": [
      "low latency",
      "agents",
      "reasoning"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 131072,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-mistral/Ministral-3B",
    "page": 1
  },
  {
    "id": "Llama-3-2-90B-Vision-Instruct",
    "registry": "azureml-meta",
    "name": "Llama-3.2-90B-Vision-Instruct",
    "original_name": "Llama-3-2-90B-Vision-Instruct",
    "friendly_name": "Llama-3.2-90B-Vision-Instruct",
    "task": "chat-completion",
    "publisher": "Meta",
    "license": "",
    "description": "",
    "summary": "Advanced image reasoning capabilities for visual understanding agentic apps.",
    "model_family": "Meta",
    "model_version": "",
    "notes": "",
    "tags": [
      "multimodal",
      "reasoning",
      "conversation"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 128000,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-meta/Llama-3-2-90B-Vision-Instruct",
    "page": 1
  },
  {
    "id": "Llama-3-2-11B-Vision-Instruct",
    "registry": "azureml-meta",
    "name": "Llama-3.2-11B-Vision-Instruct",
    "original_name": "Llama-3-2-11B-Vision-Instruct",
    "friendly_name": "Llama-3.2-11B-Vision-Instruct",
    "task": "chat-completion",
    "publisher": "Meta",
    "license": "",
    "description": "",
    "summary": "Excels in image reasoning capabilities on high-res images for visual understanding apps.",
    "model_family": "Meta",
    "model_version": "",
    "notes": "",
    "tags": [
      "multimodal",
      "reasoning",
      "conversation"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 128000,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-meta/Llama-3-2-11B-Vision-Instruct",
    "page": 1
  },
  {
    "id": "Cohere-command-r-plus-08-2024",
    "registry": "azureml-cohere",
    "name": "Cohere Command R+ 08-2024",
    "original_name": "Cohere-command-r-plus-08-2024",
    "friendly_name": "Cohere Command R+ 08-2024",
    "task": "chat-completion",
    "publisher": "Cohere",
    "license": "",
    "description": "",
    "summary": "Command R+ is a state-of-the-art RAG-optimized model designed to tackle enterprise-grade workloads.",
    "model_family": "Cohere",
    "model_version": "",
    "notes": "",
    "tags": [
      "rag",
      "multilingual"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 131072,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-cohere/Cohere-command-r-plus-08-2024",
    "page": 1
  },
  {
    "id": "Cohere-command-r-08-2024",
    "registry": "azureml-cohere",
    "name": "Cohere Command R 08-2024",
    "original_name": "Cohere-command-r-08-2024",
    "friendly_name": "Cohere Command R 08-2024",
    "task": "chat-completion",
    "publisher": "Cohere",
    "license": "",
    "description": "",
    "summary": "Command R is a scalable generative model targeting RAG and Tool Use to enable production-scale AI for enterprise.",
    "model_family": "Cohere",
    "model_version": "",
    "notes": "",
    "tags": [
      "rag",
      "multilingual"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 131072,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-cohere/Cohere-command-r-08-2024",
    "page": 1
  },
  {
    "id": "Phi-3-5-MoE-instruct",
    "registry": "azureml",
    "name": "Phi-3.5-MoE instruct (128k)",
    "original_name": "Phi-3-5-MoE-instruct",
    "friendly_name": "Phi-3.5-MoE instruct (128k)",
    "task": "chat-completion",
    "publisher": "Microsoft",
    "license": "",
    "description": "",
    "summary": "A new mixture of experts model",
    "model_family": "Microsoft",
    "model_version": "",
    "notes": "",
    "tags": [
      "reasoning",
      "understanding",
      "low latency"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 131072,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml/Phi-3-5-MoE-instruct",
    "page": 1
  },
  {
    "id": "o1-preview",
    "registry": "azure-openai",
    "name": "OpenAI o1-preview",
    "original_name": "o1-preview",
    "friendly_name": "OpenAI o1-preview",
    "task": "chat-completion",
    "publisher": "OpenAI",
    "license": "",
    "description": "",
    "summary": "Focused on advanced reasoning and solving complex problems, including math and science tasks. Ideal for applications that require deep contextual understanding and agentic workflows.",
    "model_family": "OpenAI",
    "model_version": "",
    "notes": "",
    "tags": [
      "reasoning",
      "multilingual",
      "coding"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 32768,
    "max_input_tokens": 128000,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azure-openai/o1-preview",
    "page": 1
  },
  {
    "id": "o1-mini",
    "registry": "azure-openai",
    "name": "OpenAI o1-mini",
    "original_name": "o1-mini",
    "friendly_name": "OpenAI o1-mini",
    "task": "chat-completion",
    "publisher": "OpenAI",
    "license": "",
    "description": "",
    "summary": "Smaller, faster, and 80% cheaper than o1-preview, performs well at code generation and small context operations.",
    "model_family": "OpenAI",
    "model_version": "",
    "notes": "",
    "tags": [
      "reasoning",
      "multilingual",
      "coding"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 65536,
    "max_input_tokens": 128000,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azure-openai/o1-mini",
    "page": 1
  },
  {
    "id": "Phi-3-5-vision-instruct",
    "registry": "azureml",
    "name": "Phi-3.5-vision instruct (128k)",
    "original_name": "Phi-3-5-vision-instruct",
    "friendly_name": "Phi-3.5-vision instruct (128k)",
    "task": "chat-completion",
    "publisher": "Microsoft",
    "license": "",
    "description": "",
    "summary": "Refresh of Phi-3-vision model.",
    "model_family": "Microsoft",
    "model_version": "",
    "notes": "",
    "tags": [
      "multimodal",
      "reasoning",
      "low latency"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 131072,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml/Phi-3-5-vision-instruct",
    "page": 1
  },
  {
    "id": "AI21-Jamba-1-5-Mini",
    "registry": "azureml-ai21",
    "name": "AI21 Jamba 1.5 Mini",
    "original_name": "AI21-Jamba-1-5-Mini",
    "friendly_name": "AI21 Jamba 1.5 Mini",
    "task": "chat-completion",
    "publisher": "AI21 Labs",
    "license": "",
    "description": "",
    "summary": "A 52B parameters (12B active) multilingual model, offering a 256K long context window, function calling, structured output, and grounded generation.",
    "model_family": "AI21 Labs",
    "model_version": "",
    "notes": "",
    "tags": [
      "rag",
      "multilingual",
      "large context"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 262144,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-ai21/AI21-Jamba-1-5-Mini",
    "page": 1
  },
  {
    "id": "AI21-Jamba-1-5-Large",
    "registry": "azureml-ai21",
    "name": "AI21 Jamba 1.5 Large",
    "original_name": "AI21-Jamba-1-5-Large",
    "friendly_name": "AI21 Jamba 1.5 Large",
    "task": "chat-completion",
    "publisher": "AI21 Labs",
    "license": "",
    "description": "",
    "summary": "A 398B parameters (94B active) multilingual model, offering a 256K long context window, function calling, structured output, and grounded generation.",
    "model_family": "AI21 Labs",
    "model_version": "",
    "notes": "",
    "tags": [
      "rag",
      "multilingual",
      "large context"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 262144,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-ai21/AI21-Jamba-1-5-Large",
    "page": 1
  },
  {
    "id": "Phi-3-5-mini-instruct",
    "registry": "azureml",
    "name": "Phi-3.5-mini instruct (128k)",
    "original_name": "Phi-3-5-mini-instruct",
    "friendly_name": "Phi-3.5-mini instruct (128k)",
    "task": "chat-completion",
    "publisher": "Microsoft",
    "license": "",
    "description": "",
    "summary": "Refresh of Phi-3-mini model.",
    "model_family": "Microsoft",
    "model_version": "",
    "notes": "",
    "tags": [
      "reasoning",
      "understanding",
      "low latency"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 131072,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml/Phi-3-5-mini-instruct",
    "page": 1
  },
  {
    "id": "Meta-Llama-3-1-8B-Instruct",
    "registry": "azureml-meta",
    "name": "Meta-Llama-3.1-8B-Instruct",
    "original_name": "Meta-Llama-3-1-8B-Instruct",
    "friendly_name": "Meta-Llama-3.1-8B-Instruct",
    "task": "chat-completion",
    "publisher": "Meta",
    "license": "",
    "description": "",
    "summary": "The Llama 3.1 instruction tuned text only models are optimized for multilingual dialogue use cases and outperform many of the available open source and closed chat models on common industry benchmarks.",
    "model_family": "Meta",
    "model_version": "",
    "notes": "",
    "tags": [
      "conversation"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 131072,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-meta/Meta-Llama-3-1-8B-Instruct",
    "page": 2
  },
  {
    "id": "Meta-Llama-3-1-70B-Instruct",
    "registry": "azureml-meta",
    "name": "Meta-Llama-3.1-70B-Instruct",
    "original_name": "Meta-Llama-3-1-70B-Instruct",
    "friendly_name": "Meta-Llama-3.1-70B-Instruct",
    "task": "chat-completion",
    "publisher": "Meta",
    "license": "",
    "description": "",
    "summary": "The Llama 3.1 instruction tuned text only models are optimized for multilingual dialogue use cases and outperform many of the available open source and closed chat models on common industry benchmarks.",
    "model_family": "Meta",
    "model_version": "",
    "notes": "",
    "tags": [
      "conversation"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 131072,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-meta/Meta-Llama-3-1-70B-Instruct",
    "page": 2
  },
  {
    "id": "Meta-Llama-3-1-405B-Instruct",
    "registry": "azureml-meta",
    "name": "Meta-Llama-3.1-405B-Instruct",
    "original_name": "Meta-Llama-3-1-405B-Instruct",
    "friendly_name": "Meta-Llama-3.1-405B-Instruct",
    "task": "chat-completion",
    "publisher": "Meta",
    "license": "",
    "description": "",
    "summary": "The Llama 3.1 instruction tuned text only models are optimized for multilingual dialogue use cases and outperform many of the available open source and closed chat models on common industry benchmarks.",
    "model_family": "Meta",
    "model_version": "",
    "notes": "",
    "tags": [
      "conversation"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 131072,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-meta/Meta-Llama-3-1-405B-Instruct",
    "page": 2
  },
  {
    "id": "Mistral-large-2407",
    "registry": "azureml-mistral",
    "name": "Mistral Large (2407)",
    "original_name": "Mistral-large-2407",
    "friendly_name": "Mistral Large (2407)",
    "task": "chat-completion",
    "publisher": "Mistral AI",
    "license": "",
    "description": "",
    "summary": "Mistral Large (2407) is an advanced Large Language Model (LLM) with state-of-the-art reasoning, knowledge and coding capabilities.",
    "model_family": "Mistral AI",
    "model_version": "",
    "notes": "",
    "tags": [
      "reasoning",
      "rag",
      "agents"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 131072,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-mistral/Mistral-large-2407",
    "page": 2
  },
  {
    "id": "Mistral-Nemo",
    "registry": "azureml-mistral",
    "name": "Mistral Nemo",
    "original_name": "Mistral-Nemo",
    "friendly_name": "Mistral Nemo",
    "task": "chat-completion",
    "publisher": "Mistral AI",
    "license": "",
    "description": "",
    "summary": "Mistral Nemo is a cutting-edge Language Model (LLM) boasting state-of-the-art reasoning, world knowledge, and coding capabilities within its size category.",
    "model_family": "Mistral AI",
    "model_version": "",
    "notes": "",
    "tags": [
      "reasoning",
      "rag",
      "agents"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 131072,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-mistral/Mistral-Nemo",
    "page": 2
  },
  {
    "id": "Phi-3-small-8k-instruct",
    "registry": "azureml",
    "name": "Phi-3-small instruct (8k)",
    "original_name": "Phi-3-small-8k-instruct",
    "friendly_name": "Phi-3-small instruct (8k)",
    "task": "chat-completion",
    "publisher": "Microsoft",
    "license": "",
    "description": "",
    "summary": "A 7B parameters model, proves better quality than Phi-3-mini, with a focus on high-quality, reasoning-dense data.",
    "model_family": "Microsoft",
    "model_version": "",
    "notes": "",
    "tags": [
      "reasoning",
      "understanding"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 131072,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml/Phi-3-small-8k-instruct",
    "page": 2
  },
  {
    "id": "Phi-3-small-128k-instruct",
    "registry": "azureml",
    "name": "Phi-3-small instruct (128k)",
    "original_name": "Phi-3-small-128k-instruct",
    "friendly_name": "Phi-3-small instruct (128k)",
    "task": "chat-completion",
    "publisher": "Microsoft",
    "license": "",
    "description": "",
    "summary": "Same Phi-3-small model, but with a larger context size for RAG or few shot prompting.",
    "model_family": "Microsoft",
    "model_version": "",
    "notes": "",
    "tags": [
      "reasoning",
      "understanding",
      "large context"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 131072,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml/Phi-3-small-128k-instruct",
    "page": 2
  },
  {
    "id": "Cohere-embed-v3-multilingual",
    "registry": "azureml-cohere",
    "name": "Cohere Embed v3 Multilingual",
    "original_name": "Cohere-embed-v3-multilingual",
    "friendly_name": "Cohere Embed v3 Multilingual",
    "task": "embeddings",
    "publisher": "Cohere",
    "license": "",
    "description": "",
    "summary": "Cohere Embed Multilingual is the market's leading text representation model used for semantic search, retrieval-augmented generation (RAG), classification, and clustering.",
    "model_family": "Cohere",
    "model_version": "",
    "notes": "",
    "tags": [
      "rag"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 0,
    "max_input_tokens": 512,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-cohere/Cohere-embed-v3-multilingual",
    "page": 2
  },
  {
    "id": "Cohere-embed-v3-english",
    "registry": "azureml-cohere",
    "name": "Cohere Embed v3 English",
    "original_name": "Cohere-embed-v3-english",
    "friendly_name": "Cohere Embed v3 English",
    "task": "embeddings",
    "publisher": "Cohere",
    "license": "",
    "description": "",
    "summary": "Cohere Embed English is the market's leading text representation model used for semantic search, retrieval-augmented generation (RAG), classification, and clustering.",
    "model_family": "Cohere",
    "model_version": "",
    "notes": "",
    "tags": [
      "rag"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 0,
    "max_input_tokens": 512,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-cohere/Cohere-embed-v3-english",
    "page": 2
  },
  {
    "id": "text-embedding-3-small",
    "registry": "azure-openai",
    "name": "OpenAI Text Embedding 3 (small)",
    "original_name": "text-embedding-3-small",
    "friendly_name": "OpenAI Text Embedding 3 (small)",
    "task": "embeddings",
    "publisher": "OpenAI",
    "license": "",
    "description": "",
    "summary": "Text-embedding-3 series models are the latest and most capable embedding model from OpenAI.",
    "model_family": "OpenAI",
    "model_version": "",
    "notes": "",
    "tags": [
      "rag"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 0,
    "max_input_tokens": 8191,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azure-openai/text-embedding-3-small",
    "page": 2
  },
  {
    "id": "text-embedding-3-large",
    "registry": "azure-openai",
    "name": "OpenAI Text Embedding 3 (large)",
    "original_name": "text-embedding-3-large",
    "friendly_name": "OpenAI Text Embedding 3 (large)",
    "task": "embeddings",
    "publisher": "OpenAI",
    "license": "",
    "description": "",
    "summary": "Text-embedding-3 series models are the latest and most capable embedding model from OpenAI.",
    "model_family": "OpenAI",
    "model_version": "",
    "notes": "",
    "tags": [
      "rag"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 0,
    "max_input_tokens": 8191,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azure-openai/text-embedding-3-large",
    "page": 2
  },
  {
    "id": "gpt-4o-mini",
    "registry": "azure-openai",
    "name": "OpenAI GPT-4o mini",
    "original_name": "gpt-4o-mini",
    "friendly_name": "OpenAI GPT-4o mini",
    "task": "chat-completion",
    "publisher": "OpenAI",
    "license": "",
    "description": "",
    "summary": "An affordable, efficient AI solution for diverse text and image tasks.",
    "model_family": "OpenAI",
    "model_version": "",
    "notes": "",
    "tags": [
      "multipurpose",
      "multilingual",
      "multimodal"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 131072,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azure-openai/gpt-4o-mini",
    "page": 2
  },
  {
    "id": "Cohere-command-r",
    "registry": "azureml-cohere",
    "name": "Cohere Command R",
    "original_name": "Cohere-command-r",
    "friendly_name": "Cohere Command R",
    "task": "chat-completion",
    "publisher": "Cohere",
    "license": "",
    "description": "",
    "summary": "Command R is a scalable generative model targeting RAG and Tool Use to enable production-scale AI for enterprise.",
    "model_family": "Cohere",
    "model_version": "",
    "notes": "",
    "tags": [
      "rag",
      "multilingual"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 131072,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-cohere/Cohere-command-r",
    "page": 2
  },
  {
    "id": "Cohere-command-r-plus",
    "registry": "azureml-cohere",
    "name": "Cohere Command R+",
    "original_name": "Cohere-command-r-plus",
    "friendly_name": "Cohere Command R+",
    "task": "chat-completion",
    "publisher": "Cohere",
    "license": "",
    "description": "",
    "summary": "Command R+ is a state-of-the-art RAG-optimized model designed to tackle enterprise-grade workloads.",
    "model_family": "Cohere",
    "model_version": "",
    "notes": "",
    "tags": [
      "rag",
      "multilingual"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 131072,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-cohere/Cohere-command-r-plus",
    "page": 2
  },
  {
    "id": "Mistral-large",
    "registry": "azureml-mistral",
    "name": "Mistral Large",
    "original_name": "Mistral-large",
    "friendly_name": "Mistral Large",
    "task": "chat-completion",
    "publisher": "Mistral AI",
    "license": "",
    "description": "",
    "summary": "Mistral's flagship model that's ideal for complex tasks that require large reasoning capabilities or are highly specialized (Synthetic Text Generation, Code Generation, RAG, or Agents).",
    "model_family": "Mistral AI",
    "model_version": "",
    "notes": "",
    "tags": [
      "reasoning",
      "rag",
      "agents",
      "multilingual"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 32768,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-mistral/Mistral-large",
    "page": 2
  },
  {
    "id": "Mistral-small",
    "registry": "azureml-mistral",
    "name": "Mistral Small",
    "original_name": "Mistral-small",
    "friendly_name": "Mistral Small",
    "task": "chat-completion",
    "publisher": "Mistral AI",
    "license": "",
    "description": "",
    "summary": "Mistral Small can be used on any language-based task that requires high efficiency and low latency.",
    "model_family": "Mistral AI",
    "model_version": "",
    "notes": "",
    "tags": [
      "low latency",
      "multilingual"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 32768,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-mistral/Mistral-small",
    "page": 2
  },
  {
    "id": "Meta-Llama-3-70B-Instruct",
    "registry": "azureml-meta",
    "name": "Meta-Llama-3-70B-Instruct",
    "original_name": "Meta-Llama-3-70B-Instruct",
    "friendly_name": "Meta-Llama-3-70B-Instruct",
    "task": "chat-completion",
    "publisher": "Meta",
    "license": "",
    "description": "",
    "summary": "A powerful 70-billion parameter model excelling in reasoning, coding, and broad language applications.",
    "model_family": "Meta",
    "model_version": "",
    "notes": "",
    "tags": [
      "conversation"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 8192,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-meta/Meta-Llama-3-70B-Instruct",
    "page": 2
  },
  {
    "id": "Meta-Llama-3-8B-Instruct",
    "registry": "azureml-meta",
    "name": "Meta-Llama-3-8B-Instruct",
    "original_name": "Meta-Llama-3-8B-Instruct",
    "friendly_name": "Meta-Llama-3-8B-Instruct",
    "task": "chat-completion",
    "publisher": "Meta",
    "license": "",
    "description": "",
    "summary": "A versatile 8-billion parameter model optimized for dialogue and text generation tasks.",
    "model_family": "Meta",
    "model_version": "",
    "notes": "",
    "tags": [
      "conversation"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 8192,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml-meta/Meta-Llama-3-8B-Instruct",
    "page": 2
  },
  {
    "id": "Phi-3-mini-4k-instruct",
    "registry": "azureml",
    "name": "Phi-3-mini instruct (4k)",
    "original_name": "Phi-3-mini-4k-instruct",
    "friendly_name": "Phi-3-mini instruct (4k)",
    "task": "chat-completion",
    "publisher": "Microsoft",
    "license": "",
    "description": "",
    "summary": "Tiniest member of the Phi-3 family. Optimized for both quality and low latency.",
    "model_family": "Microsoft",
    "model_version": "",
    "notes": "",
    "tags": [
      "reasoning",
      "understanding",
      "low latency"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 4096,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml/Phi-3-mini-4k-instruct",
    "page": 2
  },
  {
    "id": "Phi-3-mini-128k-instruct",
    "registry": "azureml",
    "name": "Phi-3-mini instruct (128k)",
    "original_name": "Phi-3-mini-128k-instruct",
    "friendly_name": "Phi-3-mini instruct (128k)",
    "task": "chat-completion",
    "publisher": "Microsoft",
    "license": "",
    "description": "",
    "summary": "Same Phi-3-mini model, but with a larger context size for RAG or few shot prompting.",
    "model_family": "Microsoft",
    "model_version": "",
    "notes": "",
    "tags": [
      "reasoning",
      "understanding",
      "low latency"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 131072,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml/Phi-3-mini-128k-instruct",
    "page": 2
  },
  {
    "id": "Phi-3-medium-128k-instruct",
    "registry": "azureml",
    "name": "Phi-3-medium instruct (128k)",
    "original_name": "Phi-3-medium-128k-instruct",
    "friendly_name": "Phi-3-medium instruct (128k)",
    "task": "chat-completion",
    "publisher": "Microsoft",
    "license": "",
    "description": "",
    "summary": "Same Phi-3-medium model, but with a larger context size for RAG or few shot prompting.",
    "model_family": "Microsoft",
    "model_version": "",
    "notes": "",
    "tags": [
      "reasoning",
      "understanding",
      "large context"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 131072,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml/Phi-3-medium-128k-instruct",
    "page": 3
  },
  {
    "id": "Phi-3-medium-4k-instruct",
    "registry": "azureml",
    "name": "Phi-3-medium instruct (4k)",
    "original_name": "Phi-3-medium-4k-instruct",
    "friendly_name": "Phi-3-medium instruct (4k)",
    "task": "chat-completion",
    "publisher": "Microsoft",
    "license": "",
    "description": "",
    "summary": "A 14B parameters model, proves better quality than Phi-3-mini, with a focus on high-quality, reasoning-dense data.",
    "model_family": "Microsoft",
    "model_version": "",
    "notes": "",
    "tags": [
      "reasoning",
      "understanding"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 4096,
    "max_input_tokens": 4096,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azureml/Phi-3-medium-4k-instruct",
    "page": 3
  },
  {
    "id": "gpt-4o",
    "registry": "azure-openai",
    "name": "OpenAI GPT-4o",
    "original_name": "gpt-4o",
    "friendly_name": "OpenAI GPT-4o",
    "task": "chat-completion",
    "publisher": "OpenAI",
    "license": "",
    "description": "",
    "summary": "OpenAI's most advanced multimodal model in the gpt-4o family. Can handle both text and image inputs.",
    "model_family": "OpenAI",
    "model_version": "",
    "notes": "",
    "tags": [
      "multipurpose",
      "multilingual",
      "multimodal"
    ],
    "rate_limit_tier": "",
    "supported_languages": [],
    "max_output_tokens": 16384,
    "max_input_tokens": 131072,
    "training_data_date": "",
    "evaluation": "",
    "license_description": "",
    "static_model": false,
    "supported_input_modalities": [],
    "type": "model",
    "model_url": "/marketplace/models/azure-openai/gpt-4o",
    "page": 3
  }
]